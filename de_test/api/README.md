# DE_testing_api_parser
Test for design Model data and parsing procedures for definite API

## Task 1
You need to research data from Itunes API of TOP paid applications in Russia for next tasks:
- define the model of data by spliting them to main data - some kind of daily rate of definite market research and guides which could present additional attributes of main data with relation's information for storing into DB
- make presentation of which tool you choose for scheduled ETL process into DB

## Результат 

В тексте задачи сказано, что мы собираем некоторое количество ежедневных данных для исследования рынка. Предположим, что мы хотим смотреть на динамический рейтинг 100 самых популярных платных продуктов в iTunes. Для этого нам нужно систематически отправлять запрос к API с определенными промежутками времени. Для этой цели я предлагаю использовать `Kafka`. Далее с помощью запланированных заданий в `AirFlow` данные импортируются и предобрабатыватся. Сырые данные в табличной форме записываются в файловое хранилище в формате `.parquet`.
Затем трансформируются в набор таблиц, которые сохраняются в БД. На выходе мы можем автоматизировать выгрузку запросов из БД или работать с даннами в ручном режиме. 

![etl_pipeline.jpg](https://i.ibb.co/M7Jw520/etl-pipeline-upd.jpg)

На этапе первичной предобработки данные обогащаются дополнительными признаками: ранг и время выгрузки, - и сохраняются в `.parquet` для последующего хранения.

На втором этапе данные выгружаются из хранилища, нормализуются и разбиваются на таблицы фактов и расширений в соответствии со схемой базы данных.

![db_schema.jpg](https://i.ibb.co/7KZWJq1/bd-schema.png)

В итоге в БД мы загружаем 5 таблиц:
- `product_rating` с данными о рейтинге для каждого продукта на момент выгрузки топа;
- `product` с информацией о продуктах и внешними ключами к другим расширениям;
- `author` с уникальными авторами;
- `genre` с уникальными жанрами и данными о них;
- `kind` с типом приложения. 

После того, как первичная порция данных будет загружена, в БД информация будет сохранятся неравномерно. На каждой итерации заливки данных в БД мы будем добавлять всю партицию в таблицу `product_rating`, а в остальные - только уникальные, т.е. если этих данных в таблице еще нет. 
